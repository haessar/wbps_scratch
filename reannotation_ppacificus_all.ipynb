{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /home/will/wbp_scratch/data/from_MARS/OrthoFinder/WorkingDirectory/Results_Aug21/Blast0_1.txt...\n",
      "loading /home/will/wbp_scratch/data/from_MARS/OrthoFinder/WorkingDirectory/Results_Aug21/Blast0_2.txt...\n",
      "loading /home/will/wbp_scratch/data/from_MARS/OrthoFinder/WorkingDirectory/Results_Aug21/Blast0_3.txt...\n",
      "loading /home/will/wbp_scratch/data/from_MARS/OrthoFinder/WorkingDirectory/Results_Aug21/Blast0_2.txt...\n",
      "loading /home/will/wbp_scratch/data/from_MARS/OrthoFinder/WorkingDirectory/Results_Aug21/Blast0_3.txt...\n",
      "loading /home/will/wbp_scratch/data/from_MARS/OrthoFinder/WorkingDirectory/Results_Aug21/Blast0_1.txt...\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from orthologue_analysis.orthogroups import init_orthogroup_df\n",
    "from orthologue_analysis.species import PristionchusFromTool, SpeciesList\n",
    "from orthologue_analysis.utils import SequenceIDMapping, orthofinder_paths\n",
    "from ppac_merged_split_run_utils import pickle_cache_suspicious_orthologue_pipeline\n",
    "from reannotation.analysis import (\n",
    "    interpro_accessions_frequently_missed_by_all_tools,\n",
    "    interpro_accessions_in_novel_transcripts,\n",
    "    interpro_accessions_in_missed_transcripts,\n",
    "    missed_transcripts_with_significantly_more_frequent_accessions\n",
    ")\n",
    "from reannotation.pipelines import interpro_accession_pipeline, suspicious_orthologue_pipeline, novel_orthologue_pipeline\n",
    "from reannotation.statistics import fisher_exact_for_two_lists_of_accessions\n",
    "from reannotation.utils import extract_accessions_from_transcript\n",
    "from utils.esm import extract_esm_means\n",
    "from utils.gffutils import init_db\n",
    "\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "results_label = \"Results_Aug21\"\n",
    "wbps_ann_path = \"data/from_WBPS/pristionchus_pacificus.PRJNA12644.WBPS19.annotations.gff3\"\n",
    "braker_path = \"data/from_MARS/Pristionchus_pacificus_braker3_full.gff3\"\n",
    "helixer_path = \"data/from_MARS/Pristionchus_pacificus_helixer_full.gff3\"\n",
    "anno_path = \"data/from_EBI/pristionchus_pacificus_gca000180635v4.gff3\"\n",
    "db = init_db(wbps_ann_path, \"db/Ppac_wbps.db\")\n",
    "of = orthofinder_paths(results_label, subdir=\"Orthogroups\")\n",
    "\n",
    "wbps_col = \"Ppac_LT\"\n",
    "braker_col = \"Ppac_braker3_LT\"\n",
    "helixer_col = \"Ppac_helixer_LT\"\n",
    "anno_col = \"Ppac_anno_LT\"\n",
    "\n",
    "og_df = init_orthogroup_df(of[\"orthogroups\"])\n",
    "no_og_df = init_orthogroup_df(of[\"orthogroups_unassigned_genes\"])\n",
    "seq_id_map = SequenceIDMapping(of[\"wd\"])\n",
    "mars_data_dir = os.path.join(\"data\", \"from_MARS\", \"\")\n",
    "ebi_data_dir = os.path.join(\"data\", \"from_EBI\", \"\")\n",
    "\n",
    "species_list = SpeciesList([\n",
    "    PristionchusFromTool(\"pacificus\", data_dir=mars_data_dir, data_label=\"Ppac_LT\", prot_filename_suffix=\".fa\"),\n",
    "    PristionchusFromTool(\"pacificus_braker3_reann\", data_dir=mars_data_dir, data_label=\"Ppac_braker3_LT\", prot_filename_suffix=\".fa\"),\n",
    "    PristionchusFromTool(\"pacificus_helixer_reann\", data_dir=mars_data_dir, data_label=\"Ppac_helixer_LT\", prot_filename_suffix=\".fa\"),\n",
    "    PristionchusFromTool(\"pacificus_anno_reann\", data_dir=ebi_data_dir, data_label=\"Ppac_anno_LT\", prot_filename_suffix=\".fa\")],\n",
    "    wd_path=of[\"wd\"],\n",
    "    load_blast=True\n",
    ")\n",
    "\n",
    "wbps_species = species_list.get_species_with_data_label(wbps_col)\n",
    "braker_species = species_list.get_species_with_data_label(braker_col)\n",
    "helixer_species = species_list.get_species_with_data_label(helixer_col)\n",
    "anno_species = species_list.get_species_with_data_label(anno_col)\n",
    "\n",
    "min_freq = 10\n",
    "\n",
    "interproscan_dir = \"data/from_MARS/interproscan/ppac\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared orthologues with WBPS:\n",
      "WBPS: 18931\n",
      "BRAKER3: 15968\n",
      "Helixer: 14372\n",
      "Anno: 16484\n"
     ]
    }
   ],
   "source": [
    "print(\"Shared orthologues with WBPS:\")\n",
    "print(\"WBPS: {}\".format(len(og_df[~og_df[wbps_col].isna()])))\n",
    "print(\"BRAKER3: {}\".format(len(og_df[~og_df[wbps_col].isna() & ~og_df[braker_col].isna()])))\n",
    "print(\"Helixer: {}\".format(len(og_df[~og_df[wbps_col].isna() & ~og_df[helixer_col].isna()])))\n",
    "print(\"Anno: {}\".format(len(og_df[~og_df[wbps_col].isna() & ~og_df[anno_col].isna()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing merged/split genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "braker_merged, braker_split = pickle_cache_suspicious_orthologue_pipeline(\"braker\", og_df, wbps_col, braker_col, species_list, seq_id_map, wbps_prefix=\"Transcript\")\n",
    "anno_merged, anno_split = pickle_cache_suspicious_orthologue_pipeline(\"anno\", og_df, wbps_col, anno_col, species_list, seq_id_map, wbps_prefix=\"Transcript\")\n",
    "helixer_merged, helixer_split = pickle_cache_suspicious_orthologue_pipeline(\"helixer\", og_df, wbps_col, helixer_col, species_list, seq_id_map, wbps_prefix=\"Transcript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRAKER3: merged=19, split=96, total=0.56\n",
      "Helixer: merged=349, split=591, total=4.0\n",
      "Anno: merged=958, split=100, total=7.13\n"
     ]
    }
   ],
   "source": [
    "num_genes = len(list(braker_species.db.all_features(featuretype=\"gene\")))\n",
    "print(f\"BRAKER3: merged={len(braker_merged)}, split={len(braker_split)}, total={round(100*(len(braker_split) + len(braker_merged)*2)/num_genes, 2)}\")\n",
    "num_genes = len(list(helixer_species.db.all_features(featuretype=\"gene\")))\n",
    "print(f\"Helixer: merged={len(helixer_merged)}, split={len(helixer_split)}, total={round(100*(len(helixer_split) + len(helixer_merged)*2)/num_genes, 2)}\")\n",
    "num_genes = len(list(anno_species.db.all_features(featuretype=\"gene\")))\n",
    "print(f\"Anno: merged={len(anno_merged)}, split={len(anno_split)}, total={round(100*(len(anno_split) + len(anno_merged)*2)/num_genes, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InterPro accession investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are no IPR accessions in the annotation... Will have to write brand new pipelines for dealing with PFAM domains (which are present)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel orthologues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novel transcripts (% of total predicted by tool)\n",
      "BRAKER3: 4799 (19.93%)\n",
      "Helixer: 14519 (45.06%)\n",
      "Anno: 7057 (24.95%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Novel transcripts (% of total predicted by tool)\")\n",
    "\n",
    "shared_braker_genes = len(og_df[~og_df[wbps_col].isna() & ~og_df[braker_col].isna()][braker_col].str.split(\",\").explode().unique())\n",
    "novel_braker_orths = len(og_df[og_df[wbps_col].isna() & ~og_df[braker_col].isna()][braker_col].str.split(\",\").explode().unique())\n",
    "novel_braker_ungs = len(no_og_df[no_og_df[wbps_col].isna() & ~no_og_df[braker_col].isna()][braker_col].str.split(\",\").explode().unique())\n",
    "assert shared_braker_genes + novel_braker_orths + novel_braker_ungs == len(braker_species.all_transcript_ids)\n",
    "print(f\"BRAKER3: {novel_braker_orths + novel_braker_ungs} ({round(100*(novel_braker_orths + novel_braker_ungs)/len(braker_species.all_transcript_ids), 2)}%)\")\n",
    "\n",
    "\n",
    "shared_helixer_genes = len(og_df[~og_df[wbps_col].isna() & ~og_df[helixer_col].isna()][helixer_col].str.split(\",\").explode().unique())\n",
    "novel_helixer_orths = len(og_df[og_df[wbps_col].isna() & ~og_df[helixer_col].isna()][helixer_col].str.split(\",\").explode().unique())\n",
    "novel_helixer_ungs = len(no_og_df[no_og_df[wbps_col].isna() & ~no_og_df[helixer_col].isna()][helixer_col].str.split(\",\").explode().unique())\n",
    "assert shared_helixer_genes + novel_helixer_orths + novel_helixer_ungs == len(helixer_species.all_transcript_ids)\n",
    "print(f\"Helixer: {novel_helixer_orths + novel_helixer_ungs} ({round(100*(novel_helixer_orths + novel_helixer_ungs)/len(helixer_species.all_transcript_ids), 2)}%)\")\n",
    "\n",
    "shared_anno_genes = len(og_df[~og_df[wbps_col].isna() & ~og_df[anno_col].isna()][anno_col].str.split(\",\").explode().unique())\n",
    "novel_anno_orths = len(og_df[og_df[wbps_col].isna() & ~og_df[anno_col].isna()][anno_col].str.split(\",\").explode().unique())\n",
    "novel_anno_ungs = len(no_og_df[no_og_df[wbps_col].isna() & ~no_og_df[anno_col].isna()][anno_col].str.split(\",\").explode().unique())\n",
    "assert shared_anno_genes + novel_anno_orths + novel_anno_ungs == len(anno_species.all_transcript_ids)\n",
    "print(f\"Anno: {novel_anno_orths + novel_anno_ungs} ({round(100*(novel_anno_orths + novel_anno_ungs)/len(anno_species.all_transcript_ids), 2)}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.12942808365344\n",
      "64.89034238488784\n",
      "53.90892296967584\n"
     ]
    }
   ],
   "source": [
    "# novel_orthologue_pipeline(hog_df, wbps_col, anno_col, species_list, out_dir=\"data/novel_orthologue_sequences/ppac/anno/\")\n",
    "# novel_orthologue_pipeline(hog_df, wbps_col, braker_col, species_list, out_dir=\"data/novel_orthologue_sequences/ppac/braker3/\")\n",
    "# novel_orthologue_pipeline(hog_df, wbps_col, helixer_col, species_list, out_dir=\"data/novel_orthologue_sequences/ppac/helixer/\")\n",
    "anno_esm_means = extract_esm_means(\"data/from_MARS/Ppac_esm_pLDDTs_anno.txt\").values()\n",
    "braker3_esm_means = extract_esm_means(\"data/from_MARS/Ppac_esm_pLDDTs_braker3.txt\").values()\n",
    "helixer_esm_means = extract_esm_means(\"data/from_MARS/Ppac_esm_pLDDTs_helixer.txt\").values()\n",
    "\n",
    "print(statistics.mean(map(float, anno_esm_means)))\n",
    "print(statistics.mean(map(float, braker3_esm_means)))\n",
    "print(statistics.mean(map(float, helixer_esm_means)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of means: 60.59425048046124\n",
      "% that are \"Confident\": 31.262011531069827\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cols = (\n",
    "    \"fn\",\n",
    "    \"mean\",\n",
    "    \"median\",\n",
    "    \"stdev\",\n",
    "    \"var\",\n",
    "    \"max\",\n",
    "    \"min\",\n",
    "    \"perc_confident\"\n",
    ")\n",
    "df = pd.read_csv(\"data/from_MARS/pLDDT_ppac.csv\", names=cols)\n",
    "print(f\"Mean of means: {df['mean'].mean()}\")\n",
    "print(f\"% that are \\\"Confident\\\": {100*df[df['mean'] >= 70].shape[0]/df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno = pd.read_csv(\"data/from_MARS/pLDDT_ppac_anno.csv\", names=cols)\n",
    "df_braker3 = pd.read_csv(\"data/from_MARS/pLDDT_ppac_braker3.csv\", names=cols)\n",
    "df_helixer = pd.read_csv(\"data/from_MARS/pLDDT_ppac_helixer.csv\", names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of WBPS % that are \"Confident\" residues: 36.404548366431776\n",
      "Mean of BRAKER3 % that are \"Confident\" residues: 47.615584415584415\n",
      "Mean of Anno % that are \"Confident\" residues: 43.181391378574475\n",
      "Mean of Helixer % that are \"Confident\" residues: 29.80027884280237\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean of WBPS % that are \\\"Confident\\\" residues: {df['perc_confident'].mean()}\")\n",
    "print(f\"Mean of BRAKER3 % that are \\\"Confident\\\" residues: {df_braker3['perc_confident'].mean()}\")\n",
    "print(f\"Mean of Anno % that are \\\"Confident\\\" residues: {df_anno['perc_confident'].mean()}\")\n",
    "print(f\"Mean of Helixer % that are \\\"Confident\\\" residues: {df_helixer['perc_confident'].mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
